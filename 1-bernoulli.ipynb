{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decreased-intersection",
   "metadata": {},
   "source": [
    "# LAB 5: Text classification with Naive Bayes\n",
    "\n",
    "Objectives:\n",
    "\n",
    "* Train and evaluate Naive Bayes text classifiers\n",
    "* Cross-validation\n",
    "* Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustained-diary",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from cytoolz import *\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "correct-northern",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "right-nicaragua",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\n",
    "    \"s3://ling583/rcv1-politics.parquet\", storage_options={\"anon\": True}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italian-cancer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\n",
    "    \"en_core_web_sm\",\n",
    "    exclude=[\"tagger\", \"parser\", \"ner\", \"lemmatizer\", \"attribute_ruler\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detected-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    doc = nlp.tokenizer(text)\n",
    "    return [t.norm_ for t in doc if t.is_alpha]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-census",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"tokens\"] = df[\"text\"].progress_apply(tokenize)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rubber-trunk",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Baseline dummy classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "filled-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-sierra",
   "metadata": {},
   "source": [
    "Set up five-fold cross-validation. We'll use the same training/test splits for all our experiments so the results will be easier to compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=5432)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "express-denver",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = DummyClassifier()\n",
    "cross_val_score(baseline, df[\"tokens\"], df[\"pol\"], cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fundamental-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(baseline, df[\"tokens\"], df[\"pol\"], cv=cv)\n",
    "print(classification_report(df[\"pol\"], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-simon",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "### Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-stadium",
   "metadata": {},
   "source": [
    "Set up a pipeline: first convert tokenized text into feature vectors, then apply naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = make_pipeline(CountVectorizer(analyzer=identity), BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controlled-lease",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(bnb, df[\"tokens\"], df[\"pol\"], cv=cv, n_jobs=-1)\n",
    "print(classification_report(df[\"pol\"], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-proportion",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amino-factor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(\"tcp://127.0.0.1:34795\")\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "green-question",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import RandomizedSearchCV\n",
    "from scipy.stats.distributions import loguniform, randint, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executed-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "broad-sleep",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = make_pipeline(CountVectorizer(analyzer=identity), BernoulliNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-material",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    bnb, {\"bernoullinb__alpha\": loguniform(1e-10, 10.0)}, n_iter=25, scoring=\"f1\"\n",
    ")\n",
    "search.fit(df[\"tokens\"], df[\"pol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-comparative",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-provider",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-yacht",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.plot(\n",
    "    \"param_bernoullinb__alpha\", \"mean_test_score\", kind=\"scatter\", logx=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-variable",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    bnb,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": randint(1, 5),\n",
    "        \"bernoullinb__alpha\": loguniform(1e-10, 1e-5),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1\",\n",
    ")\n",
    "search.fit(df[\"tokens\"], df[\"pol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acceptable-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_, search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "capable-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "muslim-timeline",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.plot(\"param_countvectorizer__min_df\", \"mean_test_score\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-capitol",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.plot(\n",
    "    \"param_bernoullinb__alpha\", \"mean_test_score\", kind=\"scatter\", logx=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-azerbaijan",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results.plot(\n",
    "    \"param_bernoullinb__alpha\",\n",
    "    \"mean_test_score\",\n",
    "    kind=\"scatter\",\n",
    "    logx=True,\n",
    "    c=\"param_countvectorizer__min_df\",\n",
    "    colormap=\"Set1\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intended-silence",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "search = RandomizedSearchCV(\n",
    "    bnb,\n",
    "    {\n",
    "        \"countvectorizer__min_df\": [1],\n",
    "        \"countvectorizer__max_df\": uniform(0.5, 0.5),\n",
    "        \"bernoullinb__alpha\": loguniform(1e-10, 1e-5),\n",
    "    },\n",
    "    n_iter=25,\n",
    "    scoring=\"f1\",\n",
    ")\n",
    "search.fit(df[\"tokens\"], df[\"pol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appreciated-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "search.best_params_, search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-turner",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = pd.DataFrame(search.cv_results_)\n",
    "cv_results.plot(\"param_countvectorizer__max_df\", \"mean_test_score\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romantic-rescue",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Evaluate final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fleet-butler",
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.set_params(\n",
    "    bernoullinb__alpha=1e-10, countvectorizer__min_df=1, countvectorizer__max_df=0.73\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adolescent-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = cross_val_predict(bnb, df[\"tokens\"], df[\"pol\"], cv=cv, n_jobs=-1)\n",
    "print(classification_report(df[\"pol\"], predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "behavioral-accuracy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
